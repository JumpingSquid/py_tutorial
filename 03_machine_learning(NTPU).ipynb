{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module3. Machine Learning 機器學習入門\n",
    "Machine learning is a process to let the program itself recognize the hidden pattern behind the data.\n",
    "In the past, when we want the computer to do something for us, we need to define the rule in advance.\n",
    "And the idea of machine learning, is to let the computer know the best way for handling a task by itself with training.\n",
    "This field involves traditional statistical tools like regression and more modern approach like deep learning.\n",
    "We will go through some of these technique in this module based on the titanic dataset.\n",
    "\n",
    "機器學習是一種讓電腦本身去找出資料背後的規律的過程。\n",
    "過去我們要讓電腦幫我們做事，需要給出明確的規則。而機器學習的目標是要在給定目標的情況下，讓電腦透過重複的嘗試與修正後，找出適合的方法。\n",
    "機器學習的範圍很廣，包含傳統的迴歸到現在流行的深度學習都屬於這個領域。\n",
    "\n",
    "The nature of machine learning or modelling is to find the relationship between some variables X and y. Mathematically,\n",
    "this means we and to have a function f(X) = y. The function can have many forms, like linear regression assumes y = X * W + e.\n",
    "Deep learning is also an extension of this idea. Besides, there are other non-linear models (e.g. decision tree) that\n",
    "forms a model using a series of conditions to predict y.\n",
    "\n",
    "機器學習或是所謂\"建模\"、\"模型\"的本質，就是當我們有一些自變數X，我們想找出它們跟一個應變數y的關係，以數學的方式來說，就是找出一個函數讓y = f(X)。\n",
    "f(X) 可以有很多形式，比方說線性迴歸模型就是假定 y 跟 X 之間是呈現 y = X * W + e 這樣一個線性關係。而深度學習也是這種線性模型的延伸。\n",
    "另外也有像決策樹這樣非線性的模型，透過一連串的條件判斷，依據各個條件的符合與否，來預測 y。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "We first use the data from Kaggle's clasic competition: Titanic.\n",
    "The data of Titanic dataset includes passengers' personal information, ticket information and whether they are survived or not.\n",
    "The goal of the competition is to train a model with highest accuracy for predicting the survaival.\n",
    "我們這邊使用的是來自Kaggle經典競賽:鐵達尼號的資料。\n",
    "鐵達尼號的資料中包含乘客的個人資料、船票資料以及是否在船難中活下來。比賽的目標就是要訓練一個模型來透過個人跟船票資料來預測生存機率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# as usual\n",
    "# if you are working on local environment, please change the path to \"titanic.csv\" if the file is in the same folder\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/JumpingSquid/py_tutorial/master/data/titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the column names, there is a variable, \"Survived\", indicates whether the passenger was alive.\n",
    "We will try to use different models to see if we can make a good prediction.\n",
    "\n",
    "在資料裡有欄位 \"Survived\" 代表著這名乘客是否存活，我們以下會用不同的方式來找出預測存活率的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "## 1. Train and Evaluate 訓練與評估\n",
    "In practice, machine learning tasks include (1) collect data, (2) data preprocess, (3) model training, and (4) model evaluation.\n",
    "We start from the third part model training. In general, when we want to train a model, we will have a bunch of data with\n",
    "some target to be used as the learning samples for the computer. Then we use the trained model for inference or predicting.\n",
    "But there is a problem, that is, overfitting. Overfitting means that the model is too good at the training samples, but\n",
    "performs worse when using other data.\n",
    "\n",
    "To start training a model, we need to first split the dataset into train set and test set.\n",
    "The train set is the one used to train the model, and we will use the test set to evaluate the accuracy of the model and avoid overfitting.\n",
    "\n",
    "實務上，機器學習的過程包含(1)收集資料，(2)資料預處理，(3)模型訓練，(4)模型評估。在這邊我們先針對(3)模型訓練的部分來說明。\n",
    "在訓練模型的過程中，我們通常會有一些事先收集好並標註的資料，用來作為電腦學習的範本，稱為訓練樣本(Training sample)。\n",
    "用這些資料訓練出模型之後，我們再拿模型去預測實際的資料。\n",
    "但機器學習有一個很重要的特性，就是通常我們在訓練的時候，如果模型的彈性很大(參數很多)，理論上只要訓練的時數夠長，就可以訓練出完全符合訓練樣本的模型。\n",
    "我們稱這問題為 Overfitting。\n",
    "\n",
    "你可以想像是一個考生，在考卷題目都沒有變的情況下考個一千遍，他能靠著背下問題跟答案來拿到一百分。即使他並不是真的知道為甚麼答案是這樣。\n",
    "因此，在訓練模型的過程中，我們習慣會將資料拆成訓練集(Train set)跟測試集(Test set)，確保模型不是因為Overfitting 的關係而在訓練集上拿到高分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split the dataset into training set and test set by 8:2\n",
    "split_n = int(0.8 * len(df))\n",
    "df_train = df.iloc[:split_n, :]\n",
    "df_test = df.iloc[split_n:, :]\n",
    "\n",
    "print(\"sample size of training set:\", len(df_train))\n",
    "print(\"sample size of test set:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1 Feature Selection and Preprocessing 特徵選擇與預處理\n",
    "When performing machine learning, it is important to choose right features.\n",
    "Features are the variables that the model use to predict the target value.\n",
    "In this case, passenger's gender, age, and class might be good features to predict the chance of survival.\n",
    "Although not certainly, domain knowledge can usually help you figure out what are the good features.\n",
    "\n",
    "We first select three features: Pclass, Sex, and Age. But since the gender is stored in the form of string, we need to change it to 1/0.\n",
    "Then we need to fill the nan value in the columns Age.\n",
    "\n",
    "在開始訓練之前，我們通常會先選擇一些變數作為模型預測的基準。雖然一次把全部變數都拿來用是一個很直接的作法，但因為每個變數的完整度一般不會一致。\n",
    "預先選擇一些跟預測目標比較有關聯性且資料完整的變數可以簡化訓練的過程。雖然不是一定，但如果你對問題本身的專業領域有一些認識(domain knowledge)，\n",
    "或可以選擇出更適合的特徵。\n",
    "\n",
    "在這邊我們選定資料中的三個變數做為預測的基礎:Pclass(船艙等級)、Sex(性別)、Age(年齡)。\n",
    "\n",
    "機器學習有一個重要的概念，就是不論你原先資料是數字、文字還是其他形式，目前程式可以處理的型態就是數字而已。因此，如果我們的資料中有非數字的變數，\n",
    "我們就需要將其轉成數字。由於性別在資料中是以文字記錄，在把資料交給程式之前，我們需要把它換成數字，常見的做法就是改成0跟1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_X = df_train.loc[:, [\"Pclass\", \"Sex\", \"Age\"]]\n",
    "train_X = train_X.replace(\"female\", 0)\n",
    "train_X = train_X.replace(\"male\", 1)\n",
    "train_X = train_X.fillna(0)\n",
    "train_y = df_train.Survived\n",
    "\n",
    "test_X = df_test.loc[:, [\"Pclass\", \"Sex\", \"Age\"]]\n",
    "test_X = test_X.replace(\"female\", 0)\n",
    "test_X = test_X.replace(\"male\", 1)\n",
    "test_X = test_X.fillna(0)\n",
    "test_y = df_test.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2 Model Selection 模型選擇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression 線性迴歸\n",
    "We first train a linear regression model as a benchmark.\n",
    "\n",
    "我們一開始先以一個線性迴歸作為基礎的模型。\n",
    "如前面所說的，機器學習包含的技術方法很多，所以通常我們會選定一個基本、易做的模型做為比較的基準，而線性迴歸就符合這樣的特性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_linear = LinearRegression().fit(train_X, train_y)\n",
    "print(\"R squared is\", clf_linear.score(train_X, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The mean squared error for the linear regression is\", mean_squared_error(clf_linear.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Logistic Regression\n",
    "Logistic regression is a powerful tool comparing to the linear regression when it comes to the binary case.\n",
    "Common cases include probability or purchase behavior. Logistic regression usually is considered to have equivalent performance\n",
    "with more complex models.\n",
    "\n",
    "Logistic Regression 也是相當常見且有用的模型。通常 Logisitc regression 會用於y在0~1之間的情況，比方說機率或是購買與否，也常被用在網站上(例如判斷上網的瀏覽者是真人還是爬蟲機器人)。\n",
    "在多種簡易模型中，Logistic Regression通常被認為有跟複雜模型相提並論的預測能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logistic = LogisticRegression(solver =\"lbfgs\").fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean squared error for the logistc regression is\",mean_squared_error(clf_logistic.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"logistic:\", clf_logistic.predict(test_X)[:5])\n",
    "print(\"linear:\", clf_linear.predict(test_X)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of correct guess for logistic reg:\", sum(clf_logistic.predict(test_X) == test_y))\n",
    "print(\"Accuracy: \", sum(clf_logistic.predict(test_X) == test_y)/len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "binary_output = np.where(clf_linear.predict(test_X) > 0.5, 1, 0)\n",
    "print(\"Number of correct guess for linear reg:\", sum(binary_output == test_y))\n",
    "print(\"Accuracy: \", sum(binary_output == test_y)/len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Decision Tree and Random Forest\n",
    "Among all models, decision tree based models are usually the best fit when we are pursuing better accuracy\n",
    "with sufficient computing resource. In data predicting competition like Kaggle, the forerunner usually use some kind of\n",
    "decision tree based models.\n",
    "Only a single decision tree model may not be enough; however, we can train a bunch of decision tree model and aggregate\n",
    "theirs prediction together and get better performace. And that is the starting point of the random forest model.\n",
    "\n",
    "當我們對準確率有較高的要求，同時允許使用一定的計算資源時，基於決策樹的模型通常是最好的選擇。\n",
    "現今在資料預測比賽中(如Kaggle)，獲得優勝的隊伍多數都會採用基於決策樹的演算法。\n",
    "然而，單一個決策樹的預測效果比較有限，但如果我們一口氣訓練出幾百幾千個決策樹，\n",
    "再用某種方式來總和每個決策樹的預測結果，或許就能有更好的預測力。而這也是隨機森林的出發點。\n",
    "![random_forest_1](https://github.com/JumpingSquid/py_tutorial/raw/master/image/rf_ilus.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=150, max_depth=3,random_state=0)\n",
    "clf_rf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The mean squared error for the random forest is\",mean_squared_error(clf_rf.predict(test_X), test_y))\n",
    "print(\"Number of correct guess for random forest:\", sum(clf_rf.predict(test_X) == test_y))\n",
    "print(\"Accuracy: \", sum(clf_rf.predict(test_X) == test_y)/len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering 特徵工程\n",
    "After using three basic features to train the models, we may want to add more features to improve the accuracy.\n",
    "In practice, we can transform or combine one or more existing features to create a new feature.\n",
    "This is called feature engineering. In general, if we are facing a dataset with limited sample size and features,\n",
    " feature engineering is the key to increase the performance of a model.\n",
    "\n",
    "當我們使用完原始資料的變數後，我們可能會想要使用更多的變數來提升模型的預測能力。實務上我們可以將變數做一些處理，或是把不同的變數組合在一起。\n",
    "這個過程稱為特徵工程。如果我們今天的樣本數或變數有限，特徵工程對於提升模型效果有很大的幫助。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[\"old\"] = np.where(train_X.Age > 55, 1, 0)\n",
    "train_X[\"young\"] = np.where(train_X.Age < 20, 1, 0)\n",
    "print(train_X.head())\n",
    "\n",
    "test_X[\"old\"] = np.where(test_X.Age > 55, 1, 0)\n",
    "test_X[\"young\"] = np.where(test_X.Age < 20, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[\"old_man\"] = np.where((train_X.old == 1)&(train_X.Sex==1), 1, 0)\n",
    "train_X[\"young_man\"] = np.where((train_X.young == 1)&(train_X.Sex==1), 1, 0)\n",
    "print(train_X.head())\n",
    "\n",
    "test_X[\"old_man\"] = np.where((test_X.old == 1)&(test_X.Sex==1), 1, 0)\n",
    "test_X[\"young_man\"] = np.where((test_X.young == 1)&(test_X.Sex==1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_linear = LinearRegression().fit(train_X, train_y)\n",
    "clf_logistic = LogisticRegression(solver =\"lbfgs\").fit(train_X, train_y)\n",
    "clf_rf.fit(train_X, train_y)\n",
    "\n",
    "binary_output = np.where(clf_linear.predict(test_X) > 0.5, 1, 0)\n",
    "print(\"Number of correct guess for linear reg:\", sum(binary_output == test_y))\n",
    "print(\"Number of correct guess for logistic reg:\", sum(clf_logistic.predict(test_X) == test_y))\n",
    "print(\"Number of correct guess for random forest:\", sum(clf_rf.predict(test_X) == test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## [DANGER ZONE] Deep Learning with tensorflow\n",
    "\n",
    "![neural_network_1](https://github.com/JumpingSquid/py_tutorial/raw/master/image/nn1.png)\n",
    "![neural_network_2](https://github.com/JumpingSquid/py_tutorial/raw/master/image/nn2.png)\n",
    "![neural_network_3](https://github.com/JumpingSquid/py_tutorial/raw/master/image/inception_v2_resnet.png)\n",
    "\n",
    "This is an example from tensorflow official tutorial\n",
    "(https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "probability_model = tf.keras.Sequential([model,\n",
    "                                         tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_image_id = 1\n",
    "plt.figure()\n",
    "plt.imshow(test_images[test_image_id])\n",
    "\n",
    "print(class_names[np.argmax(predictions[test_image_id])])\n",
    "print(class_names[test_labels[test_image_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some cool examples:\n",
    "https://richzhang.github.io/colorization/\n",
    "https://shunsukesaito.github.io/PIFuHD/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any comments? https://forms.gle/qTjUWM2oC2VL1iaf8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

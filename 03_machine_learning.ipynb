{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module3. Machine Learning\n",
    "Machine learning is a process to let the program itself recognize the hidden pattern behind the data. This field involves traditional statistical tools like regression and more modern approach like deep learning. We will go through some of these technique in this module based on the titanic dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as usual\n",
    "# if you are working on Google Colab, please change the path to :\n",
    "# https://raw.githubusercontent.com/JumpingSquid/py_tutorial/master/titanic.csv\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the column names, there is a variable, \"Survived\", indicates whether the passenger was alive. We will try to use different models to see if we can make a good prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train and Evaluate\n",
    "To start training a model, we need to first split the dataset into train set and test set. The train set is the one used to train the model, and we will use the test set to evaluate the accuracy of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size of training set: 712\n",
      "sample size of test set: 179\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into training set and test set by 8:2\n",
    "split_n = int(0.8 * len(df))\n",
    "df_train = df.iloc[:split_n, :]\n",
    "df_test = df.iloc[split_n:, :]\n",
    "\n",
    "print(\"sample size of training set:\", len(df_train))\n",
    "print(\"sample size of test set:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first select three features, Pclass, Sex, and Age. But since the gender is stored in the form of string, we need to change it to 1/0.\n",
    "Then we need to fill the nan value in the columns Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = df_train.loc[:, [\"Pclass\", \"Sex\", \"Age\"]]\n",
    "train_X = train_X.replace(\"female\", 0)\n",
    "train_X = train_X.replace(\"male\", 1)\n",
    "train_X = train_X.fillna(0)\n",
    "train_y = df_train.Survived\n",
    "\n",
    "test_X = df_test.loc[:, [\"Pclass\", \"Sex\", \"Age\"]]\n",
    "test_X = test_X.replace(\"female\", 0)\n",
    "test_X = test_X.replace(\"male\", 1)\n",
    "test_X = test_X.fillna(0)\n",
    "test_y = df_test.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "We first train a linear regression model as a benchmark. When performin machine learning, it is important to choose right features. Features are the variables that the model learns from. For instance, in this case, passenger's gender, age, and class might be good features to predict the chance of survival. Although not certainly, domain knowledge can usually help you figure out what are the good features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared is 0.36546584549782446\n"
     ]
    }
   ],
   "source": [
    "clf_linear = LinearRegression().fit(train_X, train_y)\n",
    "print(\"R squared is\", clf_linear.score(train_X, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error for the linear regression is 0.13624616279221732\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean squared error for the linear regression is\", mean_squared_error(clf_linear.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Logistic regression is a powerful tool comparing to the linear regression when it comes to the binary case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logistic = LogisticRegression(solver =\"lbfgs\").fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error for the logistc regression is 0.2011173184357542\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean squared error for the logistc regression is\",mean_squared_error(clf_logistic.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic: [0 0 0 0 1]\n",
      "linear: [0.37687667 0.07623216 0.19814633 0.09727519 0.91093401]\n"
     ]
    }
   ],
   "source": [
    "print(\"logistic:\", clf_logistic.predict(test_X)[:5])\n",
    "print(\"linear:\", clf_linear.predict(test_X)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct guess for logistic reg: 143\n",
      "Accuracy:  0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of correct guess for logistic reg:\", sum(clf_logistic.predict(test_X) == test_y))\n",
    "print(\"Accuracy: \", sum(clf_logistic.predict(test_X) == test_y)/len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct guess for linear reg: 143\n",
      "Accuracy:  0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "binary_output = np.where(clf_linear.predict(test_X) > 0.5, 1, 0)\n",
    "print(\"Number of correct guess for linear reg:\", sum(binary_output == test_y))\n",
    "print(\"Accuracy: \", sum(binary_output == test_y)/len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Random forest is perhaps one of the most powerful prediction models in the traditional ML tools.\n",
    "![random_forest_1](https://github.com/JumpingSquid/py_tutorial/raw/master/image/rf_ilus.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=150, max_depth=3,random_state=0)\n",
    ">>> clf_rf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error for the random forest is 0.18435754189944134\n",
      "Number of correct guess for random forest: 146\n",
      "Accuracy:  0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean squared error for the random forest is\",mean_squared_error(clf_rf.predict(test_X), test_y))\n",
    "print(\"Number of correct guess for random forest:\", sum(clf_rf.predict(test_X) == test_y))\n",
    "print(\"Accuracy: \", sum(clf_rf.predict(test_X) == test_y)/len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "After using the three basic features to train the models, we may want to add more features to improve the accuracy. In practice, we can transform or combine one or more existing features to create a new feature. This is called feature engineering. In general, if we are facing a dataset with limited sample size and features, feature engineering is the key to increase the performance of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex   Age\n",
      "0       3    1  22.0\n",
      "1       1    0  38.0\n",
      "2       3    0  26.0\n",
      "3       1    0  35.0\n",
      "4       3    1  35.0\n"
     ]
    }
   ],
   "source": [
    "print(train_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex   Age  old  young\n",
      "0       3    1  22.0    0      0\n",
      "1       1    0  38.0    0      0\n",
      "2       3    0  26.0    0      0\n",
      "3       1    0  35.0    0      0\n",
      "4       3    1  35.0    0      0\n"
     ]
    }
   ],
   "source": [
    "train_X[\"old\"] = np.where(train_X.Age > 55, 1, 0)\n",
    "train_X[\"young\"] = np.where(train_X.Age < 20, 1, 0)\n",
    "print(train_X.head())\n",
    "\n",
    "test_X[\"old\"] = np.where(test_X.Age > 55, 1, 0)\n",
    "test_X[\"young\"] = np.where(test_X.Age < 20, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex   Age  old  young  old_man  young_man\n",
      "0       3    1  22.0    0      0        0          0\n",
      "1       1    0  38.0    0      0        0          0\n",
      "2       3    0  26.0    0      0        0          0\n",
      "3       1    0  35.0    0      0        0          0\n",
      "4       3    1  35.0    0      0        0          0\n"
     ]
    }
   ],
   "source": [
    "train_X[\"old_man\"] = np.where((train_X.old == 1)&(train_X.Sex==1), 1, 0)\n",
    "train_X[\"young_man\"] = np.where((train_X.young == 1)&(train_X.Sex==1), 1, 0)\n",
    "print(train_X.head())\n",
    "\n",
    "test_X[\"old_man\"] = np.where((test_X.old == 1)&(test_X.Sex==1), 1, 0)\n",
    "test_X[\"young_man\"] = np.where((test_X.young == 1)&(test_X.Sex==1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct guess for linear reg: 143\n",
      "Number of correct guess for logistic reg: 142\n",
      "Number of correct guess for random forest: 147\n"
     ]
    }
   ],
   "source": [
    "clf_linear = LinearRegression().fit(train_X, train_y)\n",
    "clf_logistic = LogisticRegression(solver =\"lbfgs\").fit(train_X, train_y)\n",
    "clf_rf.fit(train_X, train_y)\n",
    "\n",
    "binary_output = np.where(clf_linear.predict(test_X) > 0.5, 1, 0)\n",
    "print(\"Number of correct guess for linear reg:\", sum(binary_output == test_y))\n",
    "print(\"Number of correct guess for logistic reg:\", sum(clf_logistic.predict(test_X) == test_y))\n",
    "print(\"Number of correct guess for random forest:\", sum(clf_rf.predict(test_X) == test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
